{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ni7Gw7-2jtxAMwkQh6DtZSi9eroLP7Zb",
      "authorship_tag": "ABX9TyNqro+9Hdc1AfTTNq5DwnHm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nxbnv/DMDW-5th-sem/blob/main/6thlab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNd4AiPY-Ey7",
        "outputId": "99acac82-d7df-4edc-ae50-6ec59844bbf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Count of each item (C1):\n",
            "A    1\n",
            "C    2\n",
            "D    1\n",
            "E    4\n",
            "I    1\n",
            "K    5\n",
            "M    3\n",
            "N    2\n",
            "O    3\n",
            "U    1\n",
            "Y    3\n",
            "dtype: int64\n",
            "\n",
            "Step 2: Frequent one-itemset (L1) with support >= 0.6:\n",
            "A    1\n",
            "C    2\n",
            "D    1\n",
            "E    4\n",
            "I    1\n",
            "K    5\n",
            "M    3\n",
            "N    2\n",
            "O    3\n",
            "U    1\n",
            "Y    3\n",
            "dtype: int64\n",
            "\n",
            "Step 3: Generating two-itemsets (C2):\n",
            "    support   itemsets\n",
            "0       0.8        (E)\n",
            "1       1.0        (K)\n",
            "2       0.6        (M)\n",
            "3       0.6        (O)\n",
            "4       0.6        (Y)\n",
            "5       0.8     (K, E)\n",
            "6       0.6     (E, O)\n",
            "7       0.6     (K, M)\n",
            "8       0.6     (K, O)\n",
            "9       0.6     (Y, K)\n",
            "10      0.6  (K, E, O)\n",
            "\n",
            "Step 4: Frequent two-itemsets (L2) with support >= 0.6:\n",
            "    support   itemsets\n",
            "0       0.8        (E)\n",
            "1       1.0        (K)\n",
            "2       0.6        (M)\n",
            "3       0.6        (O)\n",
            "4       0.6        (Y)\n",
            "5       0.8     (K, E)\n",
            "6       0.6     (E, O)\n",
            "7       0.6     (K, M)\n",
            "8       0.6     (K, O)\n",
            "9       0.6     (Y, K)\n",
            "10      0.6  (K, E, O)\n",
            "\n",
            "Step 5: Generating candidates for three-itemsets (C3):\n",
            "    support   itemsets\n",
            "0       0.8        (E)\n",
            "1       1.0        (K)\n",
            "2       0.6        (M)\n",
            "3       0.6        (O)\n",
            "4       0.6        (Y)\n",
            "5       0.8     (K, E)\n",
            "6       0.6     (E, O)\n",
            "7       0.6     (K, M)\n",
            "8       0.6     (K, O)\n",
            "9       0.6     (Y, K)\n",
            "10      0.6  (K, E, O)\n",
            "\n",
            "Step 6: Stopping as there are no candidates for three-itemsets.\n",
            "\n",
            "Final Frequent Itemsets (L2):\n",
            "    support   itemsets\n",
            "0       0.8        (E)\n",
            "1       1.0        (K)\n",
            "2       0.6        (M)\n",
            "3       0.6        (O)\n",
            "4       0.6        (Y)\n",
            "5       0.8     (K, E)\n",
            "6       0.6     (E, O)\n",
            "7       0.6     (K, M)\n",
            "8       0.6     (K, O)\n",
            "9       0.6     (Y, K)\n",
            "10      0.6  (K, E, O)\n",
            "\n",
            "Strong Association Rules with Confidence >= 80%:\n",
            "  antecedents consequents  antecedent support  consequent support  support  \\\n",
            "0         (K)         (E)                 1.0                 0.8      0.8   \n",
            "1         (E)         (K)                 0.8                 1.0      0.8   \n",
            "2         (O)         (E)                 0.6                 0.8      0.6   \n",
            "3         (M)         (K)                 0.6                 1.0      0.6   \n",
            "4         (O)         (K)                 0.6                 1.0      0.6   \n",
            "5         (Y)         (K)                 0.6                 1.0      0.6   \n",
            "6      (K, O)         (E)                 0.6                 0.8      0.6   \n",
            "7      (E, O)         (K)                 0.6                 1.0      0.6   \n",
            "8         (O)      (K, E)                 0.6                 0.8      0.6   \n",
            "\n",
            "   confidence  lift  leverage  conviction  zhangs_metric  \n",
            "0         0.8  1.00      0.00         1.0            0.0  \n",
            "1         1.0  1.00      0.00         inf            0.0  \n",
            "2         1.0  1.25      0.12         inf            0.5  \n",
            "3         1.0  1.00      0.00         inf            0.0  \n",
            "4         1.0  1.00      0.00         inf            0.0  \n",
            "5         1.0  1.00      0.00         inf            0.0  \n",
            "6         1.0  1.25      0.12         inf            0.5  \n",
            "7         1.0  1.00      0.00         inf            0.0  \n",
            "8         1.0  1.25      0.12         inf            0.5  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Create a DataFrame from the provided dataset\n",
        "data = {\n",
        "    'Transaction_ID': ['T100', 'T200', 'T300', 'T400', 'T500'],\n",
        "    'Items_bought': [\n",
        "        {'M', 'O', 'N', 'K', 'E', 'Y'},\n",
        "        {'D', 'O', 'N', 'K', 'E', 'Y'},\n",
        "        {'M', 'A', 'K', 'E'},\n",
        "        {'M', 'U', 'C', 'K', 'Y'},\n",
        "        {'C', 'O', 'O', 'K', 'I', 'E'}\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert the 'Items_bought' column to a list of itemsets\n",
        "df['Items_bought'] = df['Items_bought'].apply(list)\n",
        "\n",
        "# Perform one-hot encoding to prepare the data for Apriori\n",
        "oht = pd.get_dummies(df['Items_bought'].explode()).groupby(level=0).max()\n",
        "\n",
        "# Initialize step counters\n",
        "step = 1\n",
        "\n",
        "# Step 1: Scan dataset for count of each item and itemset (C1)\n",
        "print(f\"Step {step}: Count of each item (C1):\")\n",
        "c1 = oht.sum()\n",
        "print(c1)\n",
        "\n",
        "# Increment step counter\n",
        "step += 1\n",
        "\n",
        "# Step 2: Find out frequent one-itemset from C1 according to support count (L1)\n",
        "min_support = 0.6\n",
        "print(f\"\\nStep {step}: Frequent one-itemset (L1) with support >= {min_support}:\")\n",
        "l1 = c1[c1 >= min_support]\n",
        "print(l1)\n",
        "\n",
        "# Increment step counter\n",
        "step += 1\n",
        "\n",
        "# Step 3: Generate two-itemsets from L1 and find their frequency counts (C2)\n",
        "print(f\"\\nStep {step}: Generating two-itemsets (C2):\")\n",
        "c2 = apriori(oht, min_support=min_support, use_colnames=True)\n",
        "print(c2)\n",
        "\n",
        "# Increment step counter\n",
        "step += 1\n",
        "\n",
        "# Step 4: From C2, generate L2 which is the list of frequent two-itemsets\n",
        "print(f\"\\nStep {step}: Frequent two-itemsets (L2) with support >= {min_support}:\")\n",
        "l2 = c2[c2['support'] >= min_support]\n",
        "print(l2)\n",
        "\n",
        "# Increment step counter\n",
        "step += 1\n",
        "\n",
        "# Step 5: Generate C3 from L2 (candidates for three-itemset)\n",
        "print(f\"\\nStep {step}: Generating candidates for three-itemsets (C3):\")\n",
        "c3 = apriori(oht, min_support=min_support, use_colnames=True)\n",
        "print(c3)\n",
        "\n",
        "# Increment step counter\n",
        "step += 1\n",
        "\n",
        "# Step 6: Stop when not possible\n",
        "print(f\"\\nStep {step}: Stopping as there are no candidates for three-itemsets.\")\n",
        "\n",
        "# Output the final frequent itemsets (L2)\n",
        "print(\"\\nFinal Frequent Itemsets (L2):\")\n",
        "print(l2)\n",
        "\n",
        "# Set the minimum confidence threshold\n",
        "min_confidence = 0.8\n",
        "\n",
        "# Find strong association rules\n",
        "association_rules_df = association_rules(l2, metric=\"confidence\", min_threshold=min_confidence)\n",
        "\n",
        "# Print the strong association rules\n",
        "print(\"\\nStrong Association Rules with Confidence >= 80%:\")\n",
        "print(association_rules_df)\n"
      ]
    }
  ]
}